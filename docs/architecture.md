# June Compiler Architecture

- Parser
- Lexer
- type checker
- name binding
- lifetime checker
- codegen

The June compiler data model is based on the data oriented school of design (similar to an ecs, which will be used as an analogy throughout this document). The compiler parses the program and creates a flattened AST of nodes and `NodeId`s that index into the vec of nodes. You can think NodeIds as equivalent to entity identifiers in an ECS and the nodes themselves as a component of that entity. Each pass of the compiler then creates additional  vectors of information associated with those same `NodeId`s, essentially setting up additional components for each entity.

## Parser

The June parser is based on a classic recursive decent parser, using operator precedence parsing inspired by the [Shunting yard algorithm](https://en.wikipedia.org/wiki/Shunting_yard_algorithm). The parser uses the lexer's `peek` and `next` methods to perform the recursive decent parsing. At each step it will peek the next token to see if it makes sense in the current parsing context. If it does, it will consume it and continue, if not it will give up on that parsing context and attempt to reinterpret that token based on the next step in the algorithm. The June lexer never looks further ahead than the next token.

## Type Checker

The type checker walks over the AST generated by the parser starting from the outermost node, to create a new vec of type information that it associates with the nodeids of their related AST Nodes. It walks the tree in a depth first fashion (with exceptions), drilling down into the AST until it can concretely determine the types of expressions purely based on their AST node kind, then it bubbles up this type information to then determine the types of the more complex compound expressions.

The type checker checks each scope in two passes. First it finds all function signatures and stores those in a `Scope` object. The active `Scope`s for the current position being type checked are stored in a vector as a stack and act as a lookup table for information needed to type check that scope. Then, the type checker checks the function bodies, using those `Scope` lookup tables to resolve calls within the body. `Scopes` are discarded once type checking of the scope is completed, at which point the type checker then continues checking the outer `Scope`.

The typechecker does type inference to a fixed point (meaning iterating over the block repeatedly until no new type information can be determined). Bidirectional, similar to the rust model TODO: replace with more precise definition.

* Where do the two passes happen?
* is it typecheck_fun_predecl?

## Lifetime Checker

The goal of the lifetime checker is to determine the lifetime of each allocation. We associate lifetime information with all expressions that can influence the lifetime of an allocation, such as variable bindings, assignments, function calls, or returns. A nodes lifetime can be one of three things:

* Local - this value does not escape this function
* Parameter - when mutable can be used to store values and have them escape functions.
* Return Lifetimes - values returned by functions escape


```
// param lifetime example:
struct Foo { a: A }
fun bar(mut foo: Foo) {
    foo.a = new A()
}

// return lifetime example #1
fun a() -> A {
    return new A()
}

// return lifetime example #2
fun b() -> A {
    return a()
}

// return lifetime example #3
fun c() -> Foo {
    mut foo = new Foo()
        foo.a = new A()

        return foo
}
```

```
fun id(a: A) -> A {
    return a
}

```

```
    A() <-- return to here
B()
    C() <-- allocate here
    D()
E()
    ```

    We also use fixed point inference to infer lifetimes where we keep repeating the lifetime inference until they stop changing, which lets us determine that the `new A()` value in example three above has a `Return` lifetime.

    modular checking

## Codegen
